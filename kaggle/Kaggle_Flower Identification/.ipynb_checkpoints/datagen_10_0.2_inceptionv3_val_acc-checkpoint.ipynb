{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846984,
     "status": "ok",
     "timestamp": 1556016385350,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "XeOON12PCKOn",
    "outputId": "c766e254-6a8f-4276-bb02-c0b9f19c480d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 131304 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "# 授權綁定Google Drive\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0ERf1wBCHJg"
   },
   "outputs": [],
   "source": [
    "# 指定Google Drive雲端硬碟的根目錄，名為drive\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 853674,
     "status": "ok",
     "timestamp": 1556016392107,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "F3B_z-o_Bete",
    "outputId": "2a67d75d-a69f-4096-9b1b-2b29081d7f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\t\t  datagen_10_inceptionv3_val_acc.ipynb\n",
      "datagen_10_0.1_inceptionv3_val_acc.ipynb  datagen_10_xception_val_acc.ipynb\n",
      "datagen_10_0.2_inceptionv3_val_acc.ipynb  result\n",
      "datagen_10_densenet201_val_acc.ipynb\n"
     ]
    }
   ],
   "source": [
    "# 指定當前的工作目錄\n",
    "import os\n",
    "\n",
    "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
    "os.chdir(\"drive/Colab Notebooks/Kaggle_Flower Identification\") \n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856073,
     "status": "ok",
     "timestamp": 1556016394533,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "Yno3pr2GBjnb",
    "outputId": "4adce681-ed16-4970-9211-d1e412020110"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 導入所需套件\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation, Flatten\n",
    "from keras.optimizers import Nadam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 設定隨機種子\n",
    "np.random.seed(42)\n",
    "rn.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "# 設定介面與字型\n",
    "plt.style.use('ggplot')\n",
    "## 正常顯示中文為標楷體\n",
    "plt.rcParams['font.family'] = 'DFKai-SB'\n",
    "## 用來正常顯示負號\n",
    "plt.rcParams['axes.unicode_minus'] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3001354,
     "status": "ok",
     "timestamp": 1556018539840,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "TduegBBuBetl",
    "outputId": "55c3ac87-8e98-4507-9aba-62bf7ff0f5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train (2823, 224, 224, 3)\n",
      "shape of y_train (2823, 5)\n",
      "shape of x_test (2000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 資料生成函數\n",
    "def make_data(directory_names, imagesize):\n",
    "    image_of_data = []\n",
    "    label_of_data = []\n",
    "    test_id = []\n",
    "    # 讀取資料夾下所有影像\n",
    "    for i, directory_name in enumerate(directory_names):\n",
    "        for filename in os.listdir(r'./data/' + directory_name + '/'):\n",
    "            img = cv2.imread(r'./data/' + directory_name + '/' + filename)\n",
    "            img = cv2.resize(img, (imagesize, imagesize))\n",
    "            image_of_data.append(np.array(img))\n",
    "            if directory_name == 'test':\n",
    "                test_id.append(filename[:-4])\n",
    "            else:\n",
    "                label_of_data.append(i)\n",
    "    image_of_data = np.array(image_of_data)\n",
    "    label_of_data = np.array(label_of_data)\n",
    "\n",
    "    return image_of_data, test_id if directory_name == 'test' else label_of_data\n",
    "        \n",
    "# 設定參數\n",
    "train_directory_names = ['train/daisy', 'train/dandelion', 'train/rose', 'train/sunflower', 'train/tulip']\n",
    "test_directory_names = ['test']\n",
    "imagesize = 224\n",
    "\n",
    "# 套用函數\n",
    "x_train, y_train = make_data(train_directory_names, imagesize)\n",
    "x_test, test_id = make_data(test_directory_names, imagesize)\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, 5)\n",
    "\n",
    "# 輸出資料型態\n",
    "print('shape of x_train', x_train.shape)\n",
    "print('shape of y_train', y_train.shape)\n",
    "print('shape of x_test', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3003387,
     "status": "ok",
     "timestamp": 1556018541898,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "93QAE7l6Betq",
    "outputId": "d93aad72-8a54-43df-d077-0ea674666160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train (2258, 224, 224, 3)\n",
      "shape of y_train (2258, 5)\n",
      "shape of x_val (565, 224, 224, 3)\n",
      "shape of y_val (565, 5)\n"
     ]
    }
   ],
   "source": [
    "# 從train資料中分出val資料\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "print('shape of x_train', x_train.shape)\n",
    "print('shape of y_train', y_train.shape)\n",
    "print('shape of x_val', x_val.shape)\n",
    "print('shape of y_val', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrC5RoBSBetv"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# callbacks\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=15, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.8, min_lr=1e-12, monitor='val_acc', patience=3, verbose=1)\n",
    "callbacks = [earlystop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vus845259H5y"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             zoom_range=0.1, # Randomly zoom image \n",
    "                             width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                             horizontal_flip=True)  # randomly flip images\n",
    "        \n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 18057
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5630482,
     "status": "ok",
     "timestamp": 1556021169086,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "o-ONdbhHshpf",
    "outputId": "73dc5039-d674-41a0-93a3-25eb803a2da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            2565        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,854,437\n",
      "Trainable params: 22,820,005\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 48s 689ms/step - loss: 1.2485 - acc: 0.5746 - val_loss: 5.0434 - val_acc: 0.3451\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 29s 410ms/step - loss: 0.8006 - acc: 0.7119 - val_loss: 7.5879 - val_acc: 0.3044\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 28s 405ms/step - loss: 0.6693 - acc: 0.7673 - val_loss: 1.7275 - val_acc: 0.5770\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.6138 - acc: 0.7889 - val_loss: 5.0197 - val_acc: 0.3681\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 29s 408ms/step - loss: 0.5553 - acc: 0.8074 - val_loss: 2.4752 - val_acc: 0.5770\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 28s 394ms/step - loss: 0.4708 - acc: 0.8265 - val_loss: 3.7973 - val_acc: 0.3681\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.001600000075995922.\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 27s 384ms/step - loss: 0.4598 - acc: 0.8433 - val_loss: 1.8263 - val_acc: 0.6088\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 29s 416ms/step - loss: 0.3772 - acc: 0.8774 - val_loss: 1.1209 - val_acc: 0.7133\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 29s 419ms/step - loss: 0.3705 - acc: 0.8684 - val_loss: 1.9840 - val_acc: 0.6301\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 29s 417ms/step - loss: 0.3880 - acc: 0.8653 - val_loss: 1.9546 - val_acc: 0.4761\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.3642 - acc: 0.8771 - val_loss: 0.8915 - val_acc: 0.7327\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 28s 399ms/step - loss: 0.3234 - acc: 0.8855 - val_loss: 1.1566 - val_acc: 0.6938\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 29s 419ms/step - loss: 0.3218 - acc: 0.8951 - val_loss: 0.9491 - val_acc: 0.7735\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 28s 403ms/step - loss: 0.2933 - acc: 0.9006 - val_loss: 0.6883 - val_acc: 0.7894\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 28s 398ms/step - loss: 0.3073 - acc: 0.8976 - val_loss: 0.9419 - val_acc: 0.7257\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 29s 413ms/step - loss: 0.3340 - acc: 0.8944 - val_loss: 1.1406 - val_acc: 0.7646\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.2812 - acc: 0.9044 - val_loss: 0.6450 - val_acc: 0.8195\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.2415 - acc: 0.9248 - val_loss: 0.6872 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.2649 - acc: 0.9166 - val_loss: 0.9179 - val_acc: 0.7522\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 28s 405ms/step - loss: 0.2143 - acc: 0.9271 - val_loss: 1.0654 - val_acc: 0.7735\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0012800000607967378.\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.2476 - acc: 0.9208 - val_loss: 0.7434 - val_acc: 0.7593\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.1927 - acc: 0.9328 - val_loss: 0.6269 - val_acc: 0.8478\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 28s 398ms/step - loss: 0.1779 - acc: 0.9354 - val_loss: 1.0871 - val_acc: 0.7805\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 29s 409ms/step - loss: 0.1652 - acc: 0.9447 - val_loss: 0.9203 - val_acc: 0.7876\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 29s 408ms/step - loss: 0.1878 - acc: 0.9376 - val_loss: 0.7073 - val_acc: 0.8496\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.1492 - acc: 0.9471 - val_loss: 0.8327 - val_acc: 0.8230\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 29s 408ms/step - loss: 0.1837 - acc: 0.9356 - val_loss: 0.7835 - val_acc: 0.8053\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.1548 - acc: 0.9480 - val_loss: 0.7276 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0010240000672638416.\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 28s 394ms/step - loss: 0.1828 - acc: 0.9330 - val_loss: 0.4891 - val_acc: 0.8566\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 29s 411ms/step - loss: 0.1129 - acc: 0.9630 - val_loss: 0.4477 - val_acc: 0.8655\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.0953 - acc: 0.9692 - val_loss: 0.5983 - val_acc: 0.8319\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.1325 - acc: 0.9555 - val_loss: 0.9475 - val_acc: 0.7858\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 29s 410ms/step - loss: 0.1114 - acc: 0.9589 - val_loss: 0.4311 - val_acc: 0.8832\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 28s 399ms/step - loss: 0.1192 - acc: 0.9577 - val_loss: 0.6503 - val_acc: 0.8283\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 28s 406ms/step - loss: 0.1089 - acc: 0.9653 - val_loss: 0.7105 - val_acc: 0.8177\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 29s 415ms/step - loss: 0.0975 - acc: 0.9697 - val_loss: 1.1142 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0008192000910639763.\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 28s 394ms/step - loss: 0.0909 - acc: 0.9652 - val_loss: 0.7024 - val_acc: 0.8407\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 28s 396ms/step - loss: 0.0658 - acc: 0.9826 - val_loss: 0.5480 - val_acc: 0.8726\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 29s 411ms/step - loss: 0.0808 - acc: 0.9738 - val_loss: 0.6976 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0006553600542247295.\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0625 - acc: 0.9791 - val_loss: 0.4317 - val_acc: 0.8938\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.0484 - acc: 0.9829 - val_loss: 0.5377 - val_acc: 0.8832\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 29s 409ms/step - loss: 0.0400 - acc: 0.9831 - val_loss: 0.7169 - val_acc: 0.8478\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 28s 396ms/step - loss: 0.0574 - acc: 0.9846 - val_loss: 0.5388 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0005242880433797836.\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 28s 403ms/step - loss: 0.0413 - acc: 0.9866 - val_loss: 0.4953 - val_acc: 0.8885\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 29s 408ms/step - loss: 0.0301 - acc: 0.9924 - val_loss: 0.6208 - val_acc: 0.8779\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 29s 409ms/step - loss: 0.0228 - acc: 0.9946 - val_loss: 0.6130 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0004194304347038269.\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 29s 420ms/step - loss: 0.0276 - acc: 0.9886 - val_loss: 0.6345 - val_acc: 0.8885\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 28s 403ms/step - loss: 0.0238 - acc: 0.9902 - val_loss: 0.6427 - val_acc: 0.8796\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0242 - acc: 0.9906 - val_loss: 0.5808 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003355443477630615.\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 28s 407ms/step - loss: 0.0192 - acc: 0.9925 - val_loss: 0.5777 - val_acc: 0.8867\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.0177 - acc: 0.9937 - val_loss: 0.7006 - val_acc: 0.8779\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 28s 405ms/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.6112 - val_acc: 0.8991\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 29s 413ms/step - loss: 0.0118 - acc: 0.9969 - val_loss: 0.6024 - val_acc: 0.8850\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.0227 - acc: 0.9942 - val_loss: 0.6785 - val_acc: 0.8779\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.7174 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00026843547821044924.\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 29s 411ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.7323 - val_acc: 0.8796\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 29s 408ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.6785 - val_acc: 0.8832\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.0175 - acc: 0.9955 - val_loss: 0.6451 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00021474838722497226.\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.0232 - acc: 0.9937 - val_loss: 0.5955 - val_acc: 0.8920\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.5587 - val_acc: 0.8920\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 28s 399ms/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.5307 - val_acc: 0.9044\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 28s 406ms/step - loss: 0.0100 - acc: 0.9960 - val_loss: 0.5865 - val_acc: 0.9009\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 28s 405ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.6613 - val_acc: 0.8796\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 28s 407ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.6463 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00017179871210828426.\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.0104 - acc: 0.9973 - val_loss: 0.5823 - val_acc: 0.8956\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0119 - acc: 0.9960 - val_loss: 0.5876 - val_acc: 0.8885\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 29s 410ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.6214 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00013743897434324027.\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 28s 406ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.6413 - val_acc: 0.8867\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.6488 - val_acc: 0.8920\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.6291 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00010995117481797934.\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 29s 407ms/step - loss: 0.0079 - acc: 0.9969 - val_loss: 0.6234 - val_acc: 0.8991\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.6301 - val_acc: 0.9009\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 0.6838 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 8.796093752607704e-05.\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 28s 404ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.6874 - val_acc: 0.8920\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.6909 - val_acc: 0.8956\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 29s 410ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.6343 - val_acc: 0.9080\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 28s 396ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.6341 - val_acc: 0.9044\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.6289 - val_acc: 0.9027\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 30s 425ms/step - loss: 0.0071 - acc: 0.9961 - val_loss: 0.6132 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 7.036874885670842e-05.\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 28s 403ms/step - loss: 0.0062 - acc: 0.9973 - val_loss: 0.6130 - val_acc: 0.8973\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 29s 408ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.6051 - val_acc: 0.9009\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 28s 406ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6205 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 5.629499792121351e-05.\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 28s 399ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.6218 - val_acc: 0.8991\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 29s 413ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.6361 - val_acc: 0.9027\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.6429 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 4.50359977548942e-05.\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.6155 - val_acc: 0.9009\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.0029 - acc: 0.9982 - val_loss: 0.6311 - val_acc: 0.9009\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.6342 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 3.602879878599197e-05.\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 28s 398ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.6764 - val_acc: 0.8920\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 30s 427ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.6454 - val_acc: 0.8973\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 0.6494 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.8823039610870185e-05.\n",
      "Epoch 00091: early stopping\n",
      "val loss: 0.6493841685025038\n",
      "val accuracy: 0.8973451328488578\n"
     ]
    }
   ],
   "source": [
    "# Build training model\n",
    "inceptionv3 = InceptionV3(include_top=False, input_shape=(imagesize, imagesize, 3)) \n",
    "x = inceptionv3.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 添加一個全連接層\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# 添加一個分類器\n",
    "output = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=inceptionv3.input, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Nadam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                              validation_data=(x_val,y_val),\n",
    "                              verbose=1, \n",
    "                              callbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('val loss:', score[0])\n",
    "print('val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5630670,
     "status": "ok",
     "timestamp": 1556021169496,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "fV2xWmftvlHv",
    "outputId": "557dea20-bc35-41a6-c976-aaf0ed3013fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['DFKai-SB'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['DFKai-SB'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['DFKai-SB'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBKS4C+EEElIgr8QQiQhCf5CCJGE/n8aTy4BC4wlBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5631031,
     "status": "ok",
     "timestamp": 1556021169942,
     "user": {
      "displayName": "朱哲緯",
      "photoUrl": "",
      "userId": "04408769001107352297"
     },
     "user_tz": -480
    },
    "id": "fJfbGppovlx2",
    "outputId": "98dc1c90-c2e6-4aeb-c522-e195d86392c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGFh2rOzSRHX"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "pred = model.predict(x_test)\n",
    "flower_class = np.argmax(pred, axis=1)\n",
    "\n",
    "# 轉為DataFrame並儲存\n",
    "df_pred = pd.DataFrame(flower_class)\n",
    "df_pred.columns = ['flower_class']\n",
    "df_pred['id'] = test_id\n",
    "df_pred = df_pred[['id', 'flower_class']]\n",
    "df_pred.to_csv('./result/Submission_datagen_10_0.2_inceptionv3_val_acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RWzhPFSQWt9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "datagen_10_0.2_inceptionv3_val_acc.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
