# ML100-Days
## Kaggle

### [Enron Fraud Dataset](https://github.com/Lance0218/ML100-Days/tree/master/kaggle/Kaggle_Enron%20Fraud%20Dataset)

### [Kaggle_Flower Identification](https://github.com/Lance0218/ML100-Days/blob/master/kaggle/Kaggle_Flower%20Identification/datagen_10_0.2_inceptionv3_val_acc.ipynb)

## Homework
<details>
<summary>1. 資料清理數據前處理</summary>
  
  #### Day_001 資料介紹與評估指標
  #### Day_002 EDA-1/讀取資料 EDA: Data summary
  #### Day_003 3-1如何新建一個 dataframe? 3-2 如何讀取其他資料? (非 csv 的資料)
  #### Day_004 EDA: 欄位的資料類型介紹及處理
  #### Day_005 EDA: 資料分佈
  #### Day_006 EDA: Outlier 及處理
  #### Day_007 常用的數值取代：中位數與分位數 連續數值標準化
  #### Day_008 DataFrame operation Data frame merge/常用的 DataFrame 操作
  #### Day_009 EDA: correlation/相關係數簡介
  #### Day_010 EDA from Correlation
  #### Day_011 EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式 Kernel Density Estimation
  #### Day_012 EDA: 把連續型變數離散化
  #### Day_013 把連續的變數離散化
  #### Day_014 Subplots
  #### Day_015 Heatmap & Grid-plot
  #### Day_016 模型初體驗 Logistic Regression
</details>

<details>
<summary>2. 資料科學特徵工程技術</summary>
  
  #### Day_017 特徵工程簡介
  #### Day_018 特徵類型
  #### Day_019 數值型特徵 - 補缺失值與標準化
  #### Day_020 數值型特徵 - 去除離群值
  #### Day_021 數值型特徵 - 去除偏態
  #### Day_022 類別型特徵 - 基礎處理
  #### Day_023 類別型特徵 - 均值編碼
  #### Day_024 類別型特徵 - 其他進階處理
  #### Day_025 時間型特徵
  #### Day_026 特徵組合 - 數值與數值組合
  #### Day_027 特徵組合 - 類別與數值組合
  #### Day_028 特徵選擇
  #### Day_029 特徵評估
  #### Day_030 分類型特徵優化 - 葉編碼
</details>

<details>
<summary>3. 機器學習基礎模型建立</summary>
  
  #### Day_031 機器學習概論
  #### Day_032 機器學習-流程與步驟
  #### Day_033 機器如何學習? 
  #### Day_034 訓練/測試集切分的概念
  #### Day_035 regression vs. classification
  #### Day_036 評估指標選定/evaluation metrics
  #### Day_037 regression model 介紹 - 線性迴歸/羅吉斯回歸
  #### Day_038 regression model 程式碼撰寫
  #### Day_039 regression model 介紹 - LASSO 回歸/ Ridge 回歸
  #### Day_040 regression model 程式碼撰寫
  #### Day_041 tree based model - 決策樹 (Decision Tree) 模型介紹
  #### Day_042 tree based model - 決策樹程式碼撰寫
  #### Day_043 tree based model - 隨機森林 (Random Forest) 介紹
  #### Day_044 tree based model - 隨機森林程式碼撰寫
  #### Day_045 tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹
  #### Day_046 tree based model - 梯度提升機程式碼撰寫
</details>

<details>
<summary>4. 機器學習調整參數</summary>
  
  #### Day_047 超參數調整與優化
  #### Day_048 Kaggle 競賽平台介紹
</details>

<details>
<summary>5. 非監督式機器學習</summary>
  
  #### Day_054 clustering 1 非監督式機器學習簡介
  #### Day_055 clustering 2 聚類算法
  #### Day_056 clustering 2 聚類算法
  #### Day_057 clustering 3 階層分群算法
  #### Day_058 clustering 4 階層分群法
  #### Day_059 dimension reduction 1 降維方法-主成份分析
  #### Day_060 dimension reduction 1 降維方法-主成份分析
  #### Day_061 dimension reduction 2 降維方法-T-SNE
  #### Day_062 dimension reduction 2 降維方法-T-SNE
</details>

<details>
<summary>6. 深度學習理論與實作</summary>
  
  #### Day_063 神經網路介紹
  #### Day_064 OPENCV
  #### Day_065 Word2Vec
</details>

<details>
<summary>7. 初探深度學習使用Keras</summary>
  
  #### Day_066 Keras 安裝與介紹
  #### Day_067 Keras Dataset
  #### Day_068 Keras Sequential API全螢幕瀏覽
  #### Day_069 Keras Module API
  #### Day_070 Multi-layer Perception多層感知
  #### Day_071 損失函數
  #### Day_072 激活函數
  #### Day_073 Gradient Descent
  #### Day_074 Gradient Descent 數學原理
  #### Day_075 BackPropagation
  #### Day_076 optimizers
  #### Day_077 訓練神經網路的細節與技巧 - Validation and overfit
  #### Day_078 訓練神經網路前的注意事項
  #### Day_079 訓練神經網路的細節與技巧 - Learning rate effect
  #### Day_080 Compare different combinations of optimizers & learning rates
  #### Day_081 訓練神經網路的細節與技巧 - Regularization
  #### Day_082 訓練神經網路的細節與技巧 - Dropout
  #### Day_083 訓練神經網路的細節與技巧 - Batch normalization全螢幕瀏覽
  #### Day_084 Comparing combinations of Activation function, optimizer and batch_norm or not
  #### Day_085 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop
  #### Day_086 訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model
  #### Day_087 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate
  #### Day_088 訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數
  #### Day_089 訓練神經網路的細節與技巧 - 撰寫自己的 Loss function
  #### Day_090 使用傳統電腦視覺與機器學習進行影像辨識
  #### Day_091 使用傳統電腦視覺與機器學習進行影像辨識
</details>

<details>
<summary>8. 深度學習應用卷積神經網路</summary>
  
  #### Day_092 卷積神經網路 (Convolution Neural Network, CNN) 簡介
  #### Day_093 卷積神經網路架構細節
  #### Day_094 卷積神經網路 - 卷積(Convolution)層與參數調整
  #### Day_095 卷積神經網路 - 池化(Pooling)層與參數調整
  #### Day_096 Keras 中的 CNN layers
  #### Day_097 使用 CNN 完成 CIFAR-10 資料集
  #### Day_098 訓練卷積神經網路的細節與技巧 - 處理大量數據
  #### Day_099 訓練卷積神經網路的細節與技巧 - 處理小量數據
  #### Day_100 訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning)
</details>
